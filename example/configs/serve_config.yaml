serve:
  host: 0.0.0.0
  port: 21002
model:
  ckpt_dir: /home/hkz/Meta-Llama-3-8B-Instruct
  tokenizer_path: /home/hkz/Meta-Llama-3-8B-Instruct/tokenizer.model
  temperature: 0.6
  top_p: 0.9
  do_load: True # debug purpose
  seed: 0
  stop_with_eos: True
  max_seq_len: 1024 # length of prefill + decode
  cache_type: normal
  max_reqs: 16
request:
  max_new_tokens: 128
executor:
  type: normal
scheduler:
  type: fcfs
  fcfs:
    num_tasks: 16
    enable_hybrid: False
  prefill_first:
    num_tasks: 2
    enable_hybrid: False
  stride:
    num_tasks: 2
    enable_hybrid: False
  deadline:
    num_tasks: 2
    enable_hybrid: False
  prefix_align:
    num_tasks: 2
    enable_hybrid: False
  balance:
    num_tasks: 2
    enable_hybrid: False
