name: Meta-Llama-3-8B-Instruct-original
type: llama
source: "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct (Please use its \"original\" checkpoint)" # Just for displaying. No automatic download.
ckpt_dir: null # Please override this in commond line with `models.ckpt_dir=<path>`.
tokenizer_path: null # By default the same as ckpt_dir, or you can override it with `models.tokenizer_path=<path>`.
dim: 4096
n_layers: 32
n_heads: 32
n_kv_heads: 8
vocab_size: 128256
multiple_of: 1024
ffn_dim_multiplier: 1.3
norm_eps: 1e-05
rope_theta: 500000.0
