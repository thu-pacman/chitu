# 常见问题解答（FAQ）

### Q1：如果芯片本身没有FP8运算单元，要怎样直接运行FP8模型呢？
可以使用FP8格式存储权重，使用BF16格式执行运算，相当于某种w8a16，但这里的8是float8。
但由于浮点数转换操作比整数转换稍微复杂一些，所以这里面会遇到一点技术挑战。
知乎上的[这篇回答](https://www.zhihu.com/question/14928372981/answer/124606559367?utm_psn=1884175276604384926 )详细解释了格式转换中的一些关键优化点。

### Q2: FP8比BF16省算力容易理解，但为什么还会有加速？
简单来说，节省一半算力的同时还能有几倍性能加速是**比较特殊的情况**，更多时候，赤兔方案带来的是性价比而非绝对性能的提升。
关于什么时候会出现这种**比较特殊的情况**，知乎上的[这篇回答](https://www.zhihu.com/question/14928372981/answer/124606559367?utm_psn=1884175276604384926 )做了一些说明。

### Q3: 什么时候发布支持国产的版本？
目前发布的版本已经可以在部分国产芯片上编译运行，但涉及国产平台上的高性能算子实现未包含在本次开源的版本中，后续还将陆续发布。

### Q4: 为什么有了vllm、sglang、llama.cpp等开源项目的情况下，还要再搞一个chitu
尽管珠玉在前，赤兔引擎也并非重复造轮子。
赤兔更专注于现有开源项目照顾不到的方面，例如多元化国产算力支持以及企业从超小规模到大规模的平滑扩展需求。
我们认为这是对大模型开源生态的有益补充。

### Q5: 哪些场景适合用赤兔，哪些不适合
就本次发布的版本而言，面向的是拥有非H卡同时又想直接运行FP8的情况，例如有A800集群和国产卡集群的用户。
在H20平台上，由于硬件对FP8已经支持得很好，也已经有很多优秀的开源实现，使用赤兔不会立刻带来显著的提升。
当然赤兔没有放弃治疗，也会持续优化在H20等平台上的性能。
  
### Q6: 赤兔会支持纯CPU推理或者CPU+GPU推理么 
从支持算力规模从小到大平滑扩展的角度，是必然要支持的，欢迎保持关注。

